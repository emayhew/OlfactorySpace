{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Odorless Paper calculations.ipynb",
      "provenance": [
        {
          "file_id": "16bBaYW6zPpnHVvTgaMbeRaZkUJERy_PY",
          "timestamp": 1601929113594
        },
        {
          "file_id": "1_Avo8Bcy9-ATWibo34nJe3WbNJ4cYs_q",
          "timestamp": 1584575360641
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TkBEXgHd85-"
      },
      "source": [
        "## Extrapolating Odor/Odorless calculations to GDB\n",
        "\n",
        "This notebook describes some sanity checks for specific functional groups and computations for extrapolating the odor/odorless model to GDB-17."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QbrL9FkRizt"
      },
      "source": [
        "import collections\n",
        "import functools\n",
        "import os\n",
        "\n",
        "from typing import Iterable, Iterator, Optional, Text\n",
        "\n",
        "import altair as alt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit import DataStructs\n",
        "from rdkit.Chem import Crippen\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import rdMolDescriptors\n",
        "import seaborn as sns\n",
        "import sklearn.ensemble\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ7PkJnARheY"
      },
      "source": [
        "def load_csv(filename):\n",
        "  return pd.read_csv(filename, encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9KG5S8B2KGO"
      },
      "source": [
        "## Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD60LT9GZhw8"
      },
      "source": [
        "all_df = load_csv('data/AllTransportData.csv')\n",
        "# Remove hypervalent halogen compounds, which throws validation errors.\n",
        "def _is_valid_smiles(smiles: Text) -> bool:\n",
        "  \"\"\"Check if smiles string is legal, first syntax than chemistry.\n",
        "\n",
        "  Currently, all sanitization routines are applied. See rdkit documentation:\n",
        "  https://www.rdkit.org/docs/source/rdkit.Chem.rdmolops.html#rdkit.Chem.rdmolops.SanitizeFlags\n",
        "\n",
        "  Args:\n",
        "    smiles: The SMILES string (possibly illegal)\n",
        "\n",
        "  Returns:\n",
        "    Whether smiles is valid and passes sanitization checks.\n",
        "  \"\"\"\n",
        "  # Pandas generates NaN (technically a \"float\") for empty rows.\n",
        "  if not isinstance(smiles, (bytes, str)):\n",
        "    return False\n",
        "  mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
        "  if mol is None:\n",
        "    return False\n",
        "  try:\n",
        "    Chem.SanitizeMol(mol)\n",
        "    return True\n",
        "  except ValueError:\n",
        "    return False\n",
        "clean_df = all_df[all_df['SMILES'].apply(_is_valid_smiles)]\n",
        "clean_df = clean_df.set_index('SMILES')\n",
        "print(\"{} entries in the raw data\".format(len(clean_df)))\n",
        "print(\"{} / {} entries are odorous\".format(sum(clean_df['odor'] == 'Odor'), len(clean_df)))\n",
        "print(clean_df.groupby('dataset.assigned')['odor'].count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97w2tJZ0Zpvq"
      },
      "source": [
        "duplicated_smiles_mask = all_df.duplicated('SMILES', keep=False)\n",
        "assert sum(duplicated_smiles_mask) == 0, 'Duplicated SMILES found!'\n",
        "clean_df['mols'] = [Chem.MolFromSmiles(s) for s in clean_df.index]\n",
        "clean_df['crippen_logp'] = [Crippen.MolLogP(m) for m in clean_df['mols']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDOMDr8YNw4S"
      },
      "source": [
        "# Is our molecular weight calculation the same as dragon?\n",
        "mw = [Descriptors.ExactMolWt(m) for m in clean_df['mols']]\n",
        "plt.plot(mw, clean_df.MW, '.')\n",
        "plt.xlabel('RDKit MW')\n",
        "plt.ylabel('Dragon MW')\n",
        "plt.title('Comparing RDKit and Dragon MW')\n",
        "plt.axis('square');\n",
        "# Yes it is."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe30oj157i_o"
      },
      "source": [
        "LIMITS = [-50, 1000]\n",
        "# Does our Burnop BP calculation match the experimental/estimated BP?\n",
        "plt.figure(figsize=(10,4))\n",
        "gs = plt.GridSpec(1, 2, wspace=0.25)\n",
        "plt.subplot(gs[0])\n",
        "plt.plot(clean_df['boiling.point.estimate.Burnop'], clean_df.BPbest, '.')\n",
        "plt.plot(LIMITS, LIMITS, '--k')\n",
        "plt.xlabel('Burnop BP')\n",
        "plt.ylabel('Experimental or EPIsuite estimated BP')\n",
        "plt.title('Comparing Burnop BP to EPISuite BP')\n",
        "plt.axis('square')\n",
        "plt.xlim(*LIMITS)\n",
        "plt.ylim(*LIMITS)\n",
        "\n",
        "# Banks BP seems to systematically underestimate the EPISuite BP, though. What's that about?\n",
        "plt.subplot(gs[1])\n",
        "plt.plot(clean_df['boiling.point.estimate.Banks'], clean_df.BPbest, '.')\n",
        "plt.plot(LIMITS, LIMITS, '--k')\n",
        "plt.xlabel('Banks BP')\n",
        "plt.ylabel('Experimental or EPIsuite estimated BP')\n",
        "plt.title('Comparing Banks BP to EPISuite BP')\n",
        "plt.axis('square');\n",
        "plt.xlim(*LIMITS)\n",
        "plt.ylim(*LIMITS)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6pkPwvrOEWP"
      },
      "source": [
        "# How does Crippen LogP match onto MLOGP?\n",
        "plt.plot(clean_df.crippen_logp, clean_df.MLOGP, '.')\n",
        "plt.plot([-10, 10], [-10, 10], '--k')\n",
        "plt.xlabel('Crippen LogP')\n",
        "plt.ylabel('Moriguchi LogP')\n",
        "plt.title('Comparing Crippen and Moriguchi LogP\\nClipped to (-10, 10)');\n",
        "plt.axis('square')\n",
        "plt.xlim(-10, 10)\n",
        "plt.ylim(-10, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWnBuIPwtBM2"
      },
      "source": [
        "def rule_of_three_score(train_x, train_y, test_x, bp_to_use):\n",
        "  \"\"\"Rule of 3: 30 < MW < 300; numHeteroatoms < 3.\n",
        "\n",
        "  The mw/heteroatam balance is chosen so that a maximum score is obtained when\n",
        "  MW = avg(30, 300) and numHetAtoms = 0\n",
        "  and also that a score of precisely 0 is obtained when\n",
        "  (MW = avg(30, 300) and numHetAtoms = 3)  OR (MW = 30 and numHetAtoms = 0) OR (MW = 300 and numHetAtoms = 0)\n",
        "  \"\"\"\n",
        "  mw_score = np.minimum(test_x['MW'] - 30, 300 - test_x['MW'])\n",
        "  heteroatom_score = np.array([rdMolDescriptors.CalcNumHeteroatoms(mol) for mol in test_x['mols']]) * -(30 + 300) / 2 / 3\n",
        "  return (mw_score + heteroatom_score).to_numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sej7rYFkZamC"
      },
      "source": [
        "# Domains of Validity for odor/odorless models\n",
        "\n",
        "Different models might have different weaknesses. Can we draw any conclusions\n",
        "about the performance of some models on various input classes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-MxFZs1g08E"
      },
      "source": [
        "fragment_queries = {\n",
        "  'Benzene': ('c1ccccc1', False),\n",
        "  'Ester': ('[CX3](=O)O[#6]', False),\n",
        "  'Carboxylic Acid': ('[CX3](=O)[OX2H1]', False),\n",
        "  'Aldehyde or ketone': ('[$([#6][CX3](=O)[#6]),$([#6][CX3H1](=O))]', False),\n",
        "  'Alkyl (4+ carbon chain)': ('[CH2X4][CH2X4][CH2X4][CH2X4]', False),\n",
        "  'Amine': ('[NX3;H2,H1,H0;!$(NC=O);!$(NO)]', False),\n",
        "  'Organohalide': ('[#6][#9,#17,#35,#53]', False),\n",
        "  'Hydroxyl': ('[C;!$(C=O)][OX2H]', False),\n",
        "  'Ether': ('[!$(C=O);$([C&!a])][OX2&H0][!$(C=O);#6]', False),\n",
        "  'Inorganic': ('[#6]', True),\n",
        "  'Organosulfide': ('[SX2][#6]', False),\n",
        "}\n",
        "# The following fragments were tested but excluded from analysis due to tiny sample sizes or lack of odorous molecules.\n",
        "#  'Phosphate': '[$(P(~O)(~O)~O)]',\n",
        "#  'Nitro': '[NX3;$(N(~O)~O)]',\n",
        "#  'Organosulfide': '[SX2][#6]',\n",
        "#  'Metal-containing': '[Li,Na,K,Rb,Cs,Be,Mg,Ca,Sr,Ba,Sc,Ti,V,Cr,Mn,Fe,Co,Ni,Cu,Zn,Y,Zr,Nb,Mo,Tc,Ru,Rh,Pd,Ag,Al,Ta,Tl,Sn,Pb,Os,Hg,U]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmyHyaJHB0q_"
      },
      "source": [
        "## Construct an ensemble of random train-test splits\n",
        "\n",
        "This step is needed for narrower CIs on our AUROC measurements. Otherwise, each test slice has too few molecules to give a reliable AUROC metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZGobumHBz__"
      },
      "source": [
        "# Code to create splits from scratch.\n",
        "# Has random seed so it should be somewhat reproducible.\n",
        "NUM_SPLITS = 80\n",
        "splits_array = np.zeros(shape=(NUM_SPLITS, len(clean_df))) # Array indicating which molecules are in which splits.\n",
        "for random_seed in range(NUM_SPLITS):\n",
        "  train_ids, test_ids = sklearn.model_selection.train_test_split(\n",
        "      np.arange(len(clean_df)), test_size=0.2, random_state=random_seed)\n",
        "  train_ids.sort(); test_ids.sort()\n",
        "  train_x, test_x = clean_df.iloc[train_ids], clean_df.iloc[test_ids]\n",
        "  train_y = clean_df.iloc[train_ids]['odor'] == 'Odor'\n",
        "  splits_array[random_seed, train_ids] = 1\n",
        "\n",
        "assert splits_array.shape[0] == NUM_SPLITS\n",
        "splits_df = pd.DataFrame({\n",
        "    **{'split_{}'.format(i): splits_array[i]\n",
        "       for i in range(80)}}, index=clean_df.index)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9SjizTTt5x3"
      },
      "source": [
        "# Here's the actual splits we used, for full reproducibility.\n",
        "reconstructed_split_data = load_csv('data/Validity_XGB_all.csv').set_index('SMILES')\n",
        "splits_df = reconstructed_split_data.isna().astype(int)\n",
        "assert len(splits_df.columns) == NUM_SPLITS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP15zSLs_Edy"
      },
      "source": [
        "def run_model_predictions(model, bp_to_use):\n",
        "  results_df = pd.DataFrame(index=splits_df.index, columns=splits_df.columns)\n",
        "  for split_column in tqdm.tqdm(splits_df.columns):\n",
        "    train_smiles = splits_df.index[splits_df[split_column] == 1].tolist()\n",
        "    train_x = clean_df.loc[train_smiles]\n",
        "    train_y = train_x['odor'] == 'Odor'\n",
        "    test_smiles = splits_df.index[splits_df[split_column] == 0].tolist()\n",
        "    test_x = clean_df.loc[test_smiles]\n",
        "    results_df.loc[splits_df[split_column] == 0, split_column] = model(train_x, train_y, test_x, bp_to_use)\n",
        "  return results_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ6Gdg_VuyMe"
      },
      "source": [
        "model_predictions = {\n",
        "    'Rule of 3': run_model_predictions(rule_of_three_score, 'BPbest'),\n",
        "    'Transport ML': load_csv('data/Validity_XGB_transport.csv').set_index('SMILES'),\n",
        "    'Many-Feature ML': load_csv('data/Validity_XGB_all.csv').set_index('SMILES'),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i4eHiWCDzXc"
      },
      "source": [
        "model_logic_rows = []\n",
        "# For each model...\n",
        "for model_name, model_df in model_predictions.items():\n",
        "  # For each query...\n",
        "  for query_name, (query_logic, invert_logic) in tqdm.tqdm(fragment_queries.items(), position=0):\n",
        "    # Compute AUROCs across the ensemble of train/test splits, then take 95% CI.\n",
        "    bootstrap_samples = []\n",
        "    for split_column in model_df.columns:\n",
        "      split_smiles = model_df.index[~model_df[split_column].isna()]\n",
        "      split_mols = clean_df.loc[split_smiles, 'mols']\n",
        "      split_test_y = clean_df.loc[split_smiles, 'odor'] == 'Odor'\n",
        "      fragment_subset = split_smiles[split_mols.map(\n",
        "        lambda mol: mol.HasSubstructMatch(Chem.MolFromSmarts(query_logic)) != invert_logic)]\n",
        "      fragment_pred_y = model_df.loc[fragment_subset, split_column]\n",
        "      fragment_test_y = split_test_y.loc[fragment_subset]\n",
        "      try:\n",
        "        bootstrap_samples.append(sklearn.metrics.roc_auc_score(fragment_test_y, fragment_pred_y))\n",
        "      except ValueError:\n",
        "        pass\n",
        "    bootstrap_samples = sorted(bootstrap_samples)\n",
        "    midpoint = bootstrap_samples[len(bootstrap_samples)//2]\n",
        "    lower, upper = bootstrap_samples[1], bootstrap_samples[-2] # 2.5% and 97.5% estimates from sample size 80.\n",
        "    model_logic_rows.append(collections.OrderedDict((\n",
        "        ('Model', model_name),\n",
        "        ('bootstraps', len(bootstrap_samples)),\n",
        "        ('Chemical class', query_name),\n",
        "        ('AUROC', midpoint), \n",
        "        ('AUROC_lower', lower),\n",
        "        ('AUROC_upper', upper),\n",
        "    )))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBFS_BF19mCc"
      },
      "source": [
        "logic_counts = {}\n",
        "for logic_name, (query_logic, invert_logic) in fragment_queries.items():\n",
        "  matching_mols = clean_df['mols'].map(\n",
        "        lambda mol: mol.HasSubstructMatch(Chem.MolFromSmarts(query_logic)))\n",
        "  if invert_logic:\n",
        "    matching_mols = np.logical_not(matching_mols)\n",
        "  logic_counts[logic_name] = sum(matching_mols)\n",
        "\n",
        "for row in model_logic_rows:\n",
        "  row['Chemical class'] = row['Chemical class'] + ' ({})'.format(logic_counts[row['Chemical class']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kub-XOFwJ5PM"
      },
      "source": [
        "validity_df = pd.DataFrame(model_logic_rows)\n",
        "validity_df['AUROC_pretty'] = validity_df.apply(lambda row: '%.2f (%.2f, %.2f)' % (row['AUROC'], row['AUROC_lower'], row['AUROC_upper']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP4-JQs23Fpc"
      },
      "source": [
        "print(validity_df.pivot(index='Model', columns='Chemical class', values='AUROC_pretty').to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBb_LmechIQn"
      },
      "source": [
        "chart = alt.Chart(validity_df).mark_rect().encode(\n",
        "    y=alt.Y('Model', sort=[\n",
        "        'Many-Feature ML',\n",
        "        'Transport ML',\n",
        "        'Rule of 3',\n",
        "    ], axis=alt.Axis(tickBand='extent')),\n",
        "    x=alt.X('Chemical class',\n",
        "            sort=alt.EncodingSortField(field=\"AUROC\", op=\"sum\", order='descending'),\n",
        "    axis=alt.Axis(tickBand='extent')),\n",
        "    color=alt.Color('AUROC',\n",
        "                    scale=alt.Scale(scheme='redblue', domain=[0, 1])),\n",
        ").configure_axisX(\n",
        "    labelAngle=-45,\n",
        "    labelAlign=\"right\",\n",
        "    labelOffset=0,\n",
        ")\n",
        "\n",
        "chart\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svFQtGqoU4-c"
      },
      "source": [
        "# Estimating the number of odorous molecules\n",
        "\n",
        "Here we take a 100,000-element sample of GDB-17 and characterize the number of\n",
        "predicted odorous molecules, as segmented by confidence and Tanimoto distance\n",
        "from the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm02w3Z6VWk5"
      },
      "source": [
        "def _bulk_similarity(\n",
        "    mols1: Iterable[Chem.Mol],\n",
        "    mols2: Optional[Iterable[Chem.Mol]] = None) -> Iterator[np.ndarray]:\n",
        "  if mols2 is None:\n",
        "    mols2 = mols1\n",
        "  get_morgan_fp = functools.partial(Chem.rdMolDescriptors.GetMorganFingerprintAsBitVect, radius=2, nBits=2048)\n",
        "  mol1_fps = map(get_morgan_fp, mols1)\n",
        "  mol2_fps = tuple(map(get_morgan_fp, mols2))\n",
        "  for fp in mol1_fps:\n",
        "    yield DataStructs.BulkTanimotoSimilarity(fp, mol2_fps)\n",
        "\n",
        "\n",
        "def get_maximum_tanimoto_similarity(\n",
        "    molecules: Iterable[Chem.Mol],\n",
        "    reference_set: Optional[Iterable[Chem.Mol]] = None) -> np.ndarray:\n",
        "  \"\"\"Compute maximal similarity to `reference_set` for all given molecules.\n",
        "\n",
        "  Args:\n",
        "    molecules: Set of molecules to compare against a reference set.\n",
        "    reference_set: Reference set of molecules. If not specified, self-similarity\n",
        "      of `molecules` will be computed.\n",
        "\n",
        "  Returns:\n",
        "    np.array of Tanimono similarities of shape (len(molecules),)\n",
        "  \"\"\"\n",
        "  computing_self_similarity = reference_set is None\n",
        "\n",
        "  result = []\n",
        "  for i, similarities in enumerate(_bulk_similarity(molecules, reference_set)):\n",
        "    if computing_self_similarity:\n",
        "      similarities[i] = 0\n",
        "    result.append(max(similarities))\n",
        "  return np.array(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4K3nw2rWzAD"
      },
      "source": [
        "gdb_df = load_csv('data/gdb17_sample.csv').set_index('SMILES')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Aqotv9hf4l"
      },
      "source": [
        "sampling_data = [\n",
        "# HAC\tGDB_count\tsample\n",
        "(1, 3, 1,), \n",
        "(2, 6, 3,), \n",
        "(3, 14, 12,), \n",
        "(4, 47, 43,), \n",
        "(5, 219, 157,), \n",
        "(6, 1091, 945,), \n",
        "(7, 6029, 5974,), \n",
        "(8, 37435, 9959,), \n",
        "(9, 243233, 9993,), \n",
        "(10, 1670163, 9999,), \n",
        "(11, 12219460, 10000,), \n",
        "(12, 72051665, 10000,), \n",
        "(13, 836687200, 10000,), \n",
        "(14, 2921398415, 10000,), \n",
        "(15, 15084103347, 10000,), \n",
        "(16, 38033661355, 10000,), \n",
        "(17, 109481780580, 10000,), \n",
        "]\n",
        "sampling_ratios = {HAC: total / sample for HAC, total, sample in sampling_data}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwUZPX0SW5V3"
      },
      "source": [
        "gdb_df['mols'] = gdb_df.index.map(Chem.MolFromSmiles)\n",
        "gdb_df['max_tanimoto'] = get_maximum_tanimoto_similarity(gdb_df['mols'], clean_df['mols'])\n",
        "gdb_df['Count'] = gdb_df['HAC'].map(sampling_ratios)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEhUfHr_Z4g2"
      },
      "source": [
        "ax = sns.histplot(gdb_df, y='transport.ML.odor.probability', x='max_tanimoto', weights='Count', bins=(np.linspace(0, 1, 100), np.linspace(0, 1, 20)), cbar=True)\n",
        "plt.title('Molecules in GDB-17')\n",
        "plt.plot([0.4, 0.4], [0, 1], '--')\n",
        "plt.xlabel('Maximum Tanimoto similarity to training data')\n",
        "plt.ylabel('Probability of having odor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G06L_mTOtqAY"
      },
      "source": [
        "gdb_with_tanimoto = gdb_df.copy()\n",
        "for threshold in (0, 0.2, 0.3, 0.4):\n",
        "  gdb_with_tanimoto['max_tanimoto>{}'.format(threshold)] = (gdb_df.max_tanimoto > threshold) * gdb_df.Count\n",
        "melt_df = gdb_with_tanimoto.melt(id_vars='transport.ML.odor.probability', value_vars=['max_tanimoto>0', 'max_tanimoto>0.2', 'max_tanimoto>0.3', 'max_tanimoto>0.4'], var_name='Molecule group', value_name='Count')\n",
        "ax = sns.ecdfplot(data=melt_df, x=\"transport.ML.odor.probability\", hue=\"Molecule group\", complementary=True, stat='count', weights='Count', log_scale=(False,True))\n",
        "ax.invert_xaxis()\n",
        "plt.grid(axis='both')\n",
        "plt.ylim([1e4, 1e12])\n",
        "plt.title('Number of odorous molecules in GDB-17')\n",
        "plt.ylabel('Number of molecules')\n",
        "plt.xlabel('Cumulative probability of odor')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
